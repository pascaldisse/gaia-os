# Gaia OS Neural Engine Configuration
# This file configures how AI workloads are distributed to the Neural Engine

# General configuration
[general]
# Enable using the Neural Engine when available
enabled = true
# Log level: debug, info, warning, error
log_level = info
# Location for Neural Engine usage logs
log_file = /var/log/gaia/neural_engine.log

# Performance settings
[performance]
# Min batch size before sending to Neural Engine (smaller batches use CPU/GPU)
min_batch_size = 4
# Max batch size to send to Neural Engine
max_batch_size = 128
# Timeout in ms for Neural Engine operations before falling back to CPU/GPU
timeout_ms = 5000

# Model optimization settings
[model_optimization]
# Convert models to Neural Engine compatible format when possible
auto_convert = true
# Cache converted models
cache_converted_models = true
# Path to store cached models
cache_directory = /var/cache/gaia/neural_engine
# Optimize models for power efficiency
power_efficient = true

# Workload types and priority
[workload_priority]
# Higher numbers = higher priority for Neural Engine
# Lower priority workloads will use CPU/GPU when Neural Engine is busy
image_recognition = 100
natural_language_processing = 90
speech_recognition = 80
general_inference = 70
training = 10  # Training generally works better on GPU

# Model format compatibility
[compatibility]
# List of model formats that can be efficiently run on Neural Engine
compatible_formats = ["CoreML", "ONNX", "TFLite"]